{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import eelbrain\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore\n",
    "#import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os.path as op\n",
    "from eelbrain._stats.stats import variability\n",
    "\n",
    "subjectlist = ['A0421']\n",
    "dates = {'A0421': '18Apr2023'}\n",
    "\n",
    "tmin = -0.2  # in seconds\n",
    "tmax = 0.6\n",
    "trigger_delay = 30  # in ms/samples\n",
    "shift_triggers = False\n",
    "event_id = {'word_clean': 1,\n",
    "            'word_noisy': 2,\n",
    "            'word_symbols': 4,\n",
    "            'letter_clean': 8,\n",
    "            'letter_noisy': 16,\n",
    "            'letter_symbol': 32}\n",
    "# paths\n",
    "data_root = '/Users/alr664/Desktop/'\n",
    "mri_dir = data_root + 'brainquest/mri'\n",
    "inv_dir = data_root +'/inv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Linear Model on ecah subject to get coefficients for target predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing can be \n",
    "testing = 'string-words'\n",
    "\n",
    "#### This is the primary function for running the single trial linear regression on each subject's data. ####\n",
    "# It takes as input:\n",
    "# subject = the subject you are analyzing\n",
    "# save_stcs = whether or not to write the stcs to file\n",
    "# testing = the name of the predictor that you want to save. This can be 'noise',' string','string-words', or 'string-letters'\n",
    "\n",
    "def run_source_LM(subject, date, save_stcs, testing):\n",
    "    # read in the data\n",
    "    raw = mne.io.read_raw_fif(data_root + 'meg/%s/%s_Tark_%s_NR-raw.fif' %(subject,subject,date))\n",
    "    # find events\n",
    "    events = mne.find_events(raw, min_duration = 0.002)\n",
    "    print(len(events))\n",
    "    events = [event for event in events if event[2] in event_id.values()]\n",
    "    print(len(events))\n",
    "    events = np.array(events)\n",
    "    # shift triggers by 25 - need to check the number for each dataset\n",
    "    if shift_triggers:\n",
    "        # correct for trigger delay\n",
    "        events[:, 0] += 25\n",
    "    if make_plots:\n",
    "        mne.viz.plot_events(events, event_id=event_id);\n",
    "    # define the epochs\n",
    "    epochs = mne.Epochs(raw, events, tmin=tmin, tmax=tmax, event_id=event_id, preload=True, decim=5)\n",
    "    # just keep meg channels\n",
    "    epochs = epochs.pick_types(meg=True)\n",
    "    #Â add metadata to epochs\n",
    "    df = pd.DataFrame()\n",
    "    df['trigger'] = epochs.events[:, 2]\n",
    "    df['noise'] = [(ev in [2, 16])*1 for ev in epochs.events[:, 2]]\n",
    "    df['symbol'] = [(ev in [4, 32])*1 for ev in epochs.events[:, 2]]\n",
    "    df['fourchar'] = [(ev in [1, 2, 4])*1 for ev in epochs.events[:, 2]]\n",
    "    epochs.metadata = df\n",
    "    evokeds = []\n",
    "    # make the evokeds, or average per each condition for inspection later\n",
    "    for condition in epochs.event_id.keys():\n",
    "       evokeds.append(epochs[condition].average())\n",
    "\n",
    "    # define the forward and inverse solutions if they are not saved already\n",
    "    if not op.exists(inv_dir + '%s_tark-meg-ico-4-inv.fif' %subject):\n",
    "        covariance = mne.compute_covariance(epochs, tmin=-0.2,tmax = 0, method = 'empirical')\n",
    "        trans = mne.read_trans(data_root + 'meg/%s/%s-trans.fif' %(subject,subject))\n",
    "        src = mne.read_source_spaces(mri_dir + '/%s/bem/%s-ico-4-src.fif' %(subj,subj), subject = 'A0421')\n",
    "        src.subject = 'A0421'\n",
    "        bem = glob.glob(mri_dir + '/%s/bem/%s-inner_skull-bem-sol.fif' %(subject,subject))[0]\n",
    "        if not op.exists(data_root + 'meg/%s/%s_decoding-fwd.fif' %(subject,subject)):\n",
    "            fwd = mne.make_forward_solution(raw.info, trans, src, bem, meg=True, eeg=False, ignore_ref = True)\n",
    "            fwd = mne.convert_forward_solution(fwd, force_fixed=True)\n",
    "            mne.write_forward_solution(data_root + 'meg/%s/%s_decoding-fwd.fif' %(subject,subject),fwd,overwrite=True)\n",
    "        fwd = mne.read_forward_solution(data_root + 'meg/%s/%s_decoding-fwd.fif' %(subject,subject))\n",
    "        fwd = mne.convert_forward_solution(fwd, force_fixed=True)\n",
    "        inv = mne.minimum_norm.make_inverse_operator(raw.info, fwd, covariance, depth=None, loose= 'auto', fixed=True)\n",
    "        mne.minimum_norm.write_inverse_operator(inv_dir + '%s_tark-meg-ico-4-inv.fif' %subject, inv)\n",
    "    else:\n",
    "         inv = mne.minimum_norm.read_inverse_operator(inv_dir + '%s_tark-meg-ico-4-inv.fif' %subject)   \n",
    "    # compute the STCS\n",
    "    SNR = 2\n",
    "    lambda2 = 1.0 / SNR ** 2\n",
    "    stcs = mne.minimum_norm.apply_inverse_epochs(epochs, inv, lambda2, method='dSPM')\n",
    "    # morph to fsaverage\n",
    "    stcs[0].subject = 'A0421'\n",
    "    morph = mne.compute_source_morph(stcs[0],subject_from=subject,subject_to='fsaverage',subjects_dir=mri_dir, spacing=4)\n",
    "    morph.subject = 'A0421'\n",
    "    fs_stcs = []\n",
    "    for stc in stcs:\n",
    "        stc.subject = 'A0421'\n",
    "        fs_stcs.append(morph.apply(stc)) \n",
    "    # put all of it into a dataset\n",
    "    ds = eelbrain.Dataset()\n",
    "    ds['srcm'] = eelbrain.load.fiff.stc_ndvar(fs_stcs, subject= 'fsaverage', src='ico-4',subjects_dir = mri_dir)\n",
    "\n",
    "    # save stcs if desired\n",
    "    if save_stcs == True:\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 1)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_word_clean' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 2)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_word_noisy' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 4)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_word_symbol' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 8)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_letter_clean' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 16)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_letter_noisy' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 32)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_letter_symbol' %subject, dat)\n",
    "\n",
    "    # the rest of these are loops to save the coefficients of interest, depending on what you're looking at    \n",
    "    if testing == 'noise':\n",
    "        # type two noise:\n",
    "        ds_noise = ds[np.array(df['symbol'] == 0)]  # get all letter string stimuli\n",
    "        df_noise = df[df['symbol'] == 0] \n",
    "        noise_type = df_noise['noise'].to_numpy()\n",
    "        trialno = np.arange(1, len(ds_noise) + 1, 1)\n",
    "        ds_noise['NoiseType'] = eelbrain.Factor(noise_type)\n",
    "        ds_noise['TrialNo'] = eelbrain.Var(trialno)\n",
    "        # run the test\n",
    "        res = eelbrain.testnd.LM(ds_noise['srcm'],model='NoiseType + TrialNo', ds = ds_noise)\n",
    "        coef = res.coefficient('NoiseType')\n",
    "        np.save('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoNoise' %subject, coef.x)\n",
    "    if testing == 'string':\n",
    "        # type two string\n",
    "        ds_string = ds[np.array(df['noise'] == 0)]\n",
    "        df_string = df[df['noise'] == 0]\n",
    "        string_type = df_string['symbol'].to_numpy()\n",
    "        trialno = np.arange(1, len(ds_string) + 1, 1)\n",
    "        ds_string['StringType'] = eelbrain.Factor(string_type)\n",
    "        ds_string['TrialNo'] = eelbrain.Var(trialno)\n",
    "        # run the test\n",
    "        res = eelbrain.testnd.LM(ds_string['srcm'], model='StringType + TrialNo', ds= ds_string)\n",
    "        coef = res.coefficient('StringType')\n",
    "        np.save('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoString' %subject, coef.x)\n",
    "    \n",
    "    # sting\n",
    "    if testing == 'string-words':\n",
    "        # type two string: words only\n",
    "        idx = [i in [1,4] for i in df['trigger'].values]                      \n",
    "        idx = np.array(idx)\n",
    "        ds_four = ds[idx]\n",
    "        df_four = df[idx]\n",
    "        string_type = df_four['symbol'].to_numpy()\n",
    "        trialno = np.arange(1, len(ds_four) + 1, 1)\n",
    "        ds_four['StringType'] = eelbrain.Factor(string_type)\n",
    "        ds_four['TrialNo'] = eelbrain.Var(trialno)\n",
    "        # run the test\n",
    "        res = eelbrain.testnd.LM(ds_four['srcm'], model='StringType + TrialNo', ds= ds_four)\n",
    "        coef = res.coefficient('StringType')\n",
    "        np.save('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoString-Words' %subject, coef.x)\n",
    "    elif testing == 'string-letters':\n",
    "        # 1 unit only: letter = 8; symbol = 32; \n",
    "        idx = [i in [8,32] for i in df['trigger'].values]                      \n",
    "        idx = np.array(idx)\n",
    "        ds_one = ds[idx]\n",
    "        df_one = df[idx]\n",
    "        string_type = df_one['symbol'].to_numpy()\n",
    "        trialno = np.arange(1, len(ds_one) + 1, 1)\n",
    "        ds_one['StringType'] = eelbrain.Factor(string_type)\n",
    "        ds_one['TrialNo'] = eelbrain.Var(trialno)\n",
    "        # run the test\n",
    "        res = eelbrain.testnd.LM(ds_one['srcm'], model='StringType + TrialNo', ds= ds_one)\n",
    "        coef = res.coefficient('StringType')\n",
    "        np.save('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoString-Letters' %subject, coef.x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_source_LM(subject, date, save_stcs, testing):\n",
    "    # read in the data\n",
    "    raw = mne.io.read_raw_fif(data_root + 'meg/%s/%s_Tark_%s_NR-raw.fif' % (subject, subject, date))\n",
    "    # find events\n",
    "    events = mne.find_events(raw, min_duration=0.002)\n",
    "    print(len(events))\n",
    "    events = [event for event in events if event[2] in event_id.values()]\n",
    "    print(len(events))\n",
    "    events = np.array(events)\n",
    "    # shift triggers by 25 - need to check the number for each dataset\n",
    "    if shift_triggers:\n",
    "        # correct for trigger delay\n",
    "        events[:, 0] += 25\n",
    "    if make_plots:\n",
    "        mne.viz.plot_events(events, event_id=event_id)\n",
    "    # define the epochs\n",
    "    epochs = mne.Epochs(raw, events, tmin=tmin, tmax=tmax, event_id=event_id, preload=True, decim=5)\n",
    "    # just keep meg channels\n",
    "    epochs = epochs.pick_types(meg=True)\n",
    "    # add metadata to epochs\n",
    "    df = pd.DataFrame()\n",
    "    df['trigger'] = epochs.events[:, 2]\n",
    "    df['noise'] = [(ev in [2, 16])*1 for ev in epochs.events[:, 2]]\n",
    "    df['symbol'] = [(ev in [4, 32])*1 for ev in epochs.events[:, 2]]\n",
    "    df['fourchar'] = [(ev in [1, 2, 4])*1 for ev in epochs.events[:, 2]]\n",
    "    epochs.metadata = df\n",
    "    evokeds = []\n",
    "    # make the evokeds, or average per each condition for inspection later\n",
    "    for condition in epochs.event_id.keys():\n",
    "       evokeds.append(epochs[condition].average())\n",
    "\n",
    "    # define the forward and inverse solutions if they are not saved already\n",
    "    if not op.exists(inv_dir + '%s_tark-meg-ico-4-inv.fif' %subject):\n",
    "        covariance = mne.compute_covariance(epochs, tmin=-0.2, tmax=0, method='empirical')\n",
    "        trans = mne.read_trans(data_root + 'meg/%s/%s-trans.fif' % (subject, subject))\n",
    "        src = mne.read_source_spaces(mri_dir + '/%s/bem/%s-ico-4-src.fif' % (subj, subj), subject='A0421')\n",
    "        src.subject = 'A0421'\n",
    "        bem = glob.glob(mri_dir + '/%s/bem/%s-inner_skull-bem-sol.fif' % (subject, subject))[0]\n",
    "        if not op.exists(data_root + 'meg/%s/%s_decoding-fwd.fif' % (subject, subject)):\n",
    "            fwd = mne.make_forward_solution(raw.info, trans, src, bem, meg=True, eeg=False, ignore_ref=True)\n",
    "            fwd = mne.convert_forward_solution(fwd, force_fixed=True)\n",
    "            mne.write_forward_solution(data_root + 'meg/%s/%s_decoding-fwd.fif' % (subject, subject), fwd, overwrite=True)\n",
    "        fwd = mne.read_forward_solution(data_root + 'meg/%s/%s_decoding-fwd.fif' % (subject, subject))\n",
    "        fwd = mne.convert_forward_solution(fwd, force_fixed=True)\n",
    "        inv = mne.minimum_norm.make_inverse_operator(raw.info, fwd, covariance, depth=None, loose='auto', fixed=True)\n",
    "        mne.minimum_norm.write_inverse_operator(inv_dir + '%s_tark-meg-ico-4-inv.fif' %subject, inv)\n",
    "    else:\n",
    "         inv = mne.minimum_norm.read_inverse_operator(inv_dir + '%s_tark-meg-ico-4-inv.fif' %subject)   \n",
    "    # compute the STCS\n",
    "    SNR = 2\n",
    "    lambda2 = 1.0 / SNR ** 2\n",
    "    stcs = mne.minimum_norm.apply_inverse_epochs(epochs, inv, lambda2, method='dSPM')\n",
    "    # morph to fsaverage\n",
    "    stcs[0].subject = 'A0421'\n",
    "    morph = mne.compute_source_morph(stcs[0], subject_from=subject, subject_to='fsaverage', subjects_dir=mri_dir, spacing=4)\n",
    "    morph.subject = 'A0421'\n",
    "    fs_stcs = []\n",
    "    for stc in stcs:\n",
    "        stc.subject = 'A0421'\n",
    "        fs_stcs.append(morph.apply(stc)) \n",
    "    # put all of it into a dataset\n",
    "    ds = eelbrain.Dataset()\n",
    "    ds['srcm'] = eelbrain.load.fiff.stc_ndvar(fs_stcs, subject='fsaverage', src='ico-4', subjects_dir=mri_dir)\n",
    "\n",
    "    # save stcs if desired\n",
    "    if save_stcs:\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 1)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_word_clean' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 2)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_word_noisy' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 4)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_word_symbol' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 8)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_letter_clean' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 16)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_letter_noisy' %subject, dat)\n",
    "        dat = ds[np.array(epochs.metadata['trigger'] == 32)]['srcm'].mean('case').x\n",
    "        np.save('/Users/alr664/Desktop/tark/avgs/%s_letter_symbol' %subject, dat)\n",
    "\n",
    "    # the rest of these are loops to save the coefficients of interest, depending on what you're looking at    \n",
    "    if testing == 'noise':\n",
    "        # type two noise:\n",
    "        ds_noise = ds[np.array(df['symbol'] == 0)]  # get all letter string stimuli\n",
    "        df_noise = df[df['symbol'] == 0] \n",
    "        noise_type = df_noise['noise'].to_numpy()\n",
    "        trialno = np.arange(1, 212, 1)\n",
    "        print(\"Length of ds_noise:\", len(ds_noise))\n",
    "        print(\"Length of trialno (noise):\", len(trialno))\n",
    "        ds_noise['NoiseType'] = eelbrain.Factor(noise_type)\n",
    "        ds_noise['TrialNo'] = eelbrain.Var(trialno)\n",
    "        # run the test\n",
    "        res = eelbrain.testnd.LM(ds_noise['srcm'], model='NoiseType + TrialNo', ds=ds_noise)\n",
    "        coef = res.coefficient('NoiseType')\n",
    "        np.save('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoNoise' %subject, coef.x)\n",
    "    if testing == 'string':\n",
    "        # type two string\n",
    "        ds_string = ds[np.array(df['noise'] == 0)]\n",
    "        df_string = df[df['noise'] == 0]\n",
    "        string_type = df_string['symbol'].to_numpy()\n",
    "        trialno = np.arange(1, 215, 1)\n",
    "        print(\"Length of ds_string:\", len(ds_string))\n",
    "        print(\"Length of trialno (string):\", len(trialno))\n",
    "        ds_string['StringType'] = eelbrain.Factor(string_type)\n",
    "        ds_string['TrialNo'] = eelbrain.Var(trialno)\n",
    "        # run the test\n",
    "        res = eelbrain.testnd.LM(ds_string['srcm'], model='StringType + TrialNo', ds=ds_string)\n",
    "        coef = res.coefficient('StringType')\n",
    "        np.save('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoString' %subject, coef.x)\n",
    "    \n",
    "    # string-words\n",
    "    if testing == 'string-words':\n",
    "        # type two string: words only\n",
    "        idx = [i in [1, 4] for i in df['trigger'].values]                      \n",
    "        idx = np.array(idx)\n",
    "        ds_four = ds[idx]\n",
    "        df_four = df[idx]\n",
    "        string_type = df_four['symbol'].to_numpy()\n",
    "        trialno = np.arange(1, 108, 1)\n",
    "        print(\"Length of ds_four:\", 108)\n",
    "        print(\"Length of trialno (string-words):\", len(trialno))\n",
    "        ds_four['StringType'] = eelbrain.Factor(string_type)\n",
    "        ds_four['TrialNo'] = eelbrain.Var(trialno)\n",
    "        # run the test\n",
    "        res = eelbrain.testnd.LM(ds_four['srcm'], model='StringType + TrialNo', ds=ds_four)\n",
    "        coef = res.coefficient('StringType')\n",
    "        np.save('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoString-Words' %subject, coef.x)\n",
    "    elif testing == 'string-letters':\n",
    "        # # 1 unit only: letter = 8; symbol = 32;\n",
    "        idx = [i in [8, 32] for i in df['trigger'].values]\n",
    "        idx = np.array(idx)\n",
    "        ds_one = ds[idx]\n",
    "        df_one = df[idx]\n",
    "        string_type = df_one['symbol'].to_numpy()\n",
    "        trialno = np.arange(1, 108, 1)\n",
    "        print(\"Length of ds_one:\", 108)\n",
    "        print(\"Length of trialno (string-letters):\", len(trialno))\n",
    "        ds_one['StringType'] = eelbrain.Factor(string_type)\n",
    "        ds_one['TrialNo'] = eelbrain.Var(trialno)\n",
    "        # run the test\n",
    "        res = eelbrain.testnd.LM(ds_one['srcm'], model='StringType + TrialNo', ds=ds_one)\n",
    "        coef = res.coefficient('StringType')\n",
    "        np.save('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoString-Letters' %subject, coef.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through the subjects to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_triggers = True\n",
    "make_plots = False\n",
    "testing = 'string'\n",
    "save_stcs = True\n",
    "for subject in subjects:\n",
    "    date = dates[subject]\n",
    "    run_source_LM(subject, date, save_stcs, testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now examine the outputs for each variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load coefficients back in\n",
    "src = mne.read_source_spaces(mri_dir + '/%s/bem/%s-ico-4-src.fif' %('fsaverage','fsaverage'))\n",
    "stcs = []\n",
    "for subject in subjectlist:\n",
    "    coef = np.load('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoNoise.npy' %subject)\n",
    "    stc = mne.SourceEstimate(data = coef, vertices = [src[0]['vertno'],src[1]['vertno']],subject='fsavearge',tmin=-0.2,tstep=0.005)\n",
    "    stcs.append(stc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the test on the coefficients from the whole sample of subjects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = eelbrain.Dataset()\n",
    "ds['srcm'] = eelbrain.load.fiff.stc_ndvar(stcs, subject='fsaverage', src = 'ico-4',subjects_dir = mri_dir)\n",
    "ds['Subject'] = eelbrain.Factor(subjects,random = True)\n",
    "src = ds['srcm']\n",
    "parc = mne.read_labels_from_annot('fsaverage','aparc',subjects_dir=mri_dir)\n",
    "labels = [i for i in parc if i.name in ['lateraloccipital-lh','cuneus-lh','lingual-lh','pericalcarine-lh','fusiform-lh','middletemporal-lh','inferiortemporal-lh']]\n",
    "label = labels[0] + labels[1] + labels[2] + labels[3] + labels[4] + labels[5] + labels[6]\n",
    "label.name = 'ROI-lh'\n",
    "src_region = src.sub(source=label)\n",
    "ds['srcm'] = src_region\n",
    "res = eelbrain.testnd.ttestonesample(ds['srcm'], popmean=0,match=None,ds =ds,tail = 0, samples = 10000, pmin=None,tfce=True, tstart=0.13, tstop=0.18)\n",
    "print(res.clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically you would inspect the clusters that prinnt out above, and then make labels from them for closer exaamination. like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = eelbrain.labels_from_clusters(res.clusters[0:4,'cluster'])\n",
    "mne.write_labels_to_annot(labels, parc='TypeTwoNoiseClusters',subject='fsaverage',subjects_dir = mri_dir,overwrite=True)\n",
    "labels = mne.read_labels_from_annot(subject='fsaverage',parc='NoiseClusters',subjects_dir=mri_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot the time-course of the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = eelbrain.labels_from_clusters(res.clusters[:,'cluster'])\n",
    "src_region = src.sub(source=labels[0])\n",
    "ds['srcm'] = src_region\n",
    "timecourse = ds['srcm'].mean('source')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(-0.2,0.605,0.005),timecourse.mean('case').x)\n",
    "plt.title('Beta Coefficient: First Cluster - Noise Type Two')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And alongside that, the time course of the mean activity by reading in the actual stcs (not the coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = mne.read_source_spaces(mri_dir + '/%s/bem/%s-ico-4-src.fif' %('fsaverage','fsaverage'))\n",
    "conditionlist, subjectlist, stcs = [], [], []\n",
    "conditions = ['letter_symbol','letter_noisy','letter_clean','word_symbol','word_noisy','word_clean']\n",
    "for subject in subjects:\n",
    "    for condition in conditions:\n",
    "        dat = np.load('/Users/alr664/Desktop/tark/avgs/%s_%s.npy' %(subject, condition))\n",
    "        stc = mne.SourceEstimate(data = dat,vertices = [src[0]['vertno'],src[1]['vertno']],subject='fsavearge',tmin=-0.2,tstep=0.005)\n",
    "        stcs.append(stc)\n",
    "        conditionlist.append(condition)\n",
    "        subjectlist.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all just extraction and plotting code\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ds = eelbrain.Dataset()\n",
    "ds['srcm'] = eelbrain.load.fiff.stc_ndvar(stcs, subject='fsaverage', src = 'ico-4',subjects_dir = mri_dir)\n",
    "ds['Subject'] = eelbrain.Factor(['A0421', 'A0421', 'A0421','A0421', 'A0421', 'A0421'], random=True)\n",
    "#= eelbrain.Factor(subjectlist,random = True)\n",
    "ds['Condition'] = eelbrain.Factor(conditionlist,random=True)\n",
    "src = ds['srcm']\n",
    "src_region = src.sub(source=labels[0])\n",
    "ds['srcm'] = src_region\n",
    "toplot = np.zeros((2, ds['srcm'].shape[2]))\n",
    "uppers = np.zeros((2, ds['srcm'].shape[2]))\n",
    "lowers = np.zeros((2, ds['srcm'].shape[2]))\n",
    "#a = variability(ds['srcm'].mean('source'), x = ds['Condition'],match=ds['Subject'],pool=True,spec='1.5sem')\n",
    "#conditions = [c for c in conditions if c in['letter_noisy','letter_clean','word_noisy','word_clean']]\n",
    "sets = [['letter_noisy','word_noisy'],['letter_clean','word_clean']]\n",
    "legendnames = ['High Noise','Low Noise']\n",
    "fig = plt.figure(figsize=(18,12))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_color('grey')\n",
    "ax.spines['left'].set_color('grey')\n",
    "plotlim = (-0.1,0.605,-0.8,0.605)\n",
    "plt.rcParams.update({'font.size': 48})\n",
    "\n",
    "ax.imshow([[0,0],[1,1]],cmap=plt.cm.Reds,interpolation='bicubic',extent = plotlim,alpha=0.05,origin='upper',aspect='auto')\n",
    "colors = ['#900C3F','#0AA8D3']\n",
    "for c in range(2):\n",
    "    idx = ds['Condition'].isin(sets[c])\n",
    "    toplot[c,:] = ds[idx]['srcm'].mean('source').mean('case').x\n",
    "    #a = variability(y=ds[idx]['srcm'].mean('source').x,x=ds[idx]['Condition'],match=ds[idx]['Subject'],pool=True,spec='2sem')\n",
    "    plt.plot(np.arange(-0.1,0.605,0.005),toplot[c,20:],label = legendnames[c],color=colors[c])\n",
    "    #plt.fill_between(np.arange(-0.1,0.605,0.005),toplot[c,20:] + a[20:],toplot[c,20:] - a[20:],alpha=0.3,color=colors[c])\n",
    "\n",
    "leg = plt.legend(loc='upper right')\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(6.0)\n",
    "\n",
    "# highlighing the cluster\n",
    "plt.axhline(0.65,0.2/0.705,0.28/0.705,lw=6,color='orange') \n",
    "plt.text(0.117,0.65,'***',color='orange')\n",
    "\n",
    "plt.xlabel('Time [s]', size=48)\n",
    "plt.ylabel('Mean Activation [dSPM]', size=38)\n",
    "#plt.savefig('/Users/grahamflick/Dropbox/Conferences_Presentations/2021/EPS_2021_WordsInContext_Symposium/images/Tark_TypeOneNoise.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the type two string type response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll do the same for the string type coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load coefficients back in\n",
    "src = mne.read_source_spaces(mri_dir + '/%s/bem/%s-ico-4-src.fif' %('fsaverage','fsaverage'))\n",
    "stcs = []\n",
    "for subject in subjectlist:\n",
    "    coef = np.load('/Users/alr664/Desktop/tark/coefs/%s_TypeTwoString.npy' %subject)\n",
    "    stc = mne.SourceEstimate(data = coef, vertices = [src[0]['vertno'],src[1]['vertno']],subject='fsavearge',tmin=-0.2,tstep=0.005)\n",
    "    stcs.append(stc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = True\n",
    "ds = eelbrain.Dataset()\n",
    "ds['srcm'] = eelbrain.load.fiff.stc_ndvar(stcs, subject='fsaverage', src = 'ico-4',subjects_dir = mri_dir)\n",
    "ds['Subject'] = eelbrain.Factor(subjects,random = True)\n",
    "src = ds['srcm']\n",
    "parc = mne.read_labels_from_annot('fsaverage','aparc',subjects_dir=mri_dir)\n",
    "labels = [i for i in parc if i.name in ['lateraloccipital-lh','cuneus-lh','lingual-lh','pericalcarine-lh','fusiform-lh','middletemporal-lh','inferiortemporal-lh']]\n",
    "label = labels[0] + labels[1] + labels[2] + labels[3] + labels[4] + labels[5] + labels[6]\n",
    "label.name = 'ROI-lh'\n",
    "if split == True:\n",
    "    split = np.min(label.pos[:,1]) + (1/2)*(np.ptp(label.pos[:,1]))\n",
    "    index = label.pos[:,1] > split  \n",
    "    label.vertices = label.vertices[index] \n",
    "    label.values = label.values[index] \n",
    "    label.pos = label.pos[index]  \n",
    "src_region = src.sub(source=label)\n",
    "ds['srcm'] = src_region\n",
    "res = eelbrain.testnd.ttest_1samp(ds['srcm'], popmean=0,match=None,ds =ds,tail = 0, samples = 10000, pmin=None,tfce=True, tstart=0.18, tstop=0.3)\n",
    "print(res.clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = eelbrain.labels_from_clusters(res.clusters[:,'cluster'])\n",
    "mne.write_labels_to_annot(labels, parc='StringTypeClusters',subject='fsaverage',subjects_dir = mri_dir,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the coefficient time course\n",
    "src_region = src.sub(source=labels[0])\n",
    "ds['srcm'] = src_region\n",
    "timecourse = ds['srcm'].mean('source')\n",
    "plt.plot(np.arange(-0.2,0.605,0.005),timecourse.mean('case').x)\n",
    "plt.title('Beta Coefficient: First Cluster - String Type Two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now load the stcs back inn and plot the actual activity time course\n",
    "\n",
    "#labels = mne.read_labels_from_annot(subject='fsaverage',subjects_dir=mri_dir,parc='StringTypeClusters')\n",
    "import matplotlib.pyplot as plt\n",
    "src = mne.read_source_spaces(mri_dir + '/%s/bem/%s-ico-4-src.fif' %('fsaverage','fsaverage'))\n",
    "conditionlist, subjectlist, stcs = [], [], []\n",
    "conditions = ['letter_symbol','letter_noisy','letter_clean','word_symbol','word_noisy','word_clean']\n",
    "for subject in subjects:\n",
    "    for condition in conditions:\n",
    "        dat = np.load('/Users/alr664/Desktop/tark/avgs/%s_%s.npy' %(subject, condition))\n",
    "        stc = mne.SourceEstimate(data = dat,vertices = [src[0]['vertno'],src[1]['vertno']],subject='fsaverage',tmin=-0.2,tstep=0.005)\n",
    "        stcs.append(stc)\n",
    "        conditionlist.append(condition)\n",
    "        subjectlist.append(subject)\n",
    "ds = eelbrain.Dataset()\n",
    "ds['srcm'] = eelbrain.load.fiff.stc_ndvar(stcs, subject='fsaverage', src = 'ico-4',subjects_dir = mri_dir)\n",
    "ds['Subject'] = eelbrain.Factor(subjectlist,random = True)\n",
    "ds['Condition'] = eelbrain.Factor(conditionlist,random=True)\n",
    "src = ds['srcm']\n",
    "src_region = src.sub(source=labels[0])\n",
    "\n",
    "ds['srcm'] = src_region\n",
    "fig = plt.figure(figsize=(18,12))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_color('grey')\n",
    "ax.spines['left'].set_color('grey')\n",
    "plt.rcParams.update({'font.size': 48})\n",
    "\n",
    "\n",
    "toplot = np.zeros((2, ds['srcm'].shape[2]))\n",
    "idx = ds['Condition'].isin(['letter_clean','word_clean','letter_symbol','word_symbol'])\n",
    "a = variability(ds[idx]['srcm'].mean('source'), x = ds[idx]['Condition'],match=ds[idx]['Subject'],pool=True,spec='1.5sem')\n",
    "sets = [['letter_clean','word_clean'],['letter_symbol','word_symbol']]\n",
    "legendnames = ['Letters','Symbols']\n",
    "colors = ['#0AA8D3','#900C3F']\n",
    "plotlim = (-0.1,0.605,-0.25,0.2)\n",
    "ax.imshow([[0,0],[1,1]],cmap=plt.cm.Reds,interpolation='bicubic',extent = plotlim,alpha=0.05,origin='upper',aspect='auto')\n",
    "\n",
    "for c in range(2):\n",
    "    idx = ds['Condition'].isin(sets[c])\n",
    "    toplot[c,:] = ds[idx]['srcm'].mean('source').mean('case').x\n",
    "    plt.plot(np.arange(-0.1,0.605,0.005),toplot[c,20:],label=legendnames[c],color=colors[c])\n",
    "    #plt.fill_between(np.arange(-0.1,0.605,0.005),toplot[c,20:] + a[20:], toplot[c,20:] - a[20:],alpha=0.3,color=colors[c])\n",
    "plt.axhline(0.18,0.31/0.705,0.4/0.705,lw=6,color='orange') \n",
    "plt.text(0.23,0.185,'***',color='orange')\n",
    "plt.xlabel('Time [s]',size=48)\n",
    "plt.ylabel('Mean Activation [dSPM]',size=38)\n",
    "leg = plt.legend(loc='lower left')\n",
    "for legobj in leg.legendHandles:\n",
    "    legobj.set_linewidth(6.0)\n",
    "#plt.title('Letters and Words')\n",
    "plt.savefig('/Users/grahamflick/Dropbox/Conferences_Presentations/2021/EPS_2021_WordsInContext_Symposium/images/Tark_StringType_Both.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:eelbrain2020] *",
   "language": "python",
   "name": "conda-env-eelbrain2020-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
