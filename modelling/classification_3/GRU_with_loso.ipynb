{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d531b-699a-428e-956b-35d48434cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "event_id_all = {'0Suff w/ Lat.': 1,\n",
    "                '0Suff w/o Lat.': 2,\n",
    "                '0Suff NW': 4,\n",
    "\n",
    "                '1Suff w/ Lat.': 11,\n",
    "                '1Suff w/o Lat.': 12,\n",
    "                '1Suff PseudoStemNW': 14,\n",
    "                '1Suff RealStemNW': 15,\n",
    "\n",
    "                '2Suff w/ Lat.': 21,\n",
    "                '2Suff w/o Lat.': 22,\n",
    "                '2Suff Composite': 23,\n",
    "                '2Suff PseudoStemNW': 24,\n",
    "                '2Suff RealStemNW': 25\n",
    "                }\n",
    "\n",
    "def get_condition(id):\n",
    "    for event in event_id_all:\n",
    "        if event_id_all[event] == id:\n",
    "            return event\n",
    "\n",
    "import mne\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "epoch_files = glob('/scratch/alr664/multiple_affix/meg/*/*epo.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ff152-e901-4c4f-9f1a-cdc8da1530d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/scratch/alr664/multiple_affix'\n",
    "meg = root + '/meg'\n",
    "logs = root + '/logs'\n",
    "\n",
    "full_dataset = [\"A0394\", \"A0421\", \"A0446\", \"A0451\", \"A0468\", \"A0484\", \"A0495\", \"A0502\", \"A0503\", \"A0508\", \n",
    "                \"A0509\", \"A0512\", \"A0513\", \"A0514\", \"A0516\", \"A0517\", \"A0518\", \"A0519\", \"A0520\", \"A0521\", \n",
    "                \"A0522\", \"A0523\", \"A0524\", \"A0525\"]\n",
    "\n",
    "subjects = [subj for subj in os.listdir(meg) if not subj.startswith('.')]\n",
    "subjects\n",
    "len(subjects)\n",
    "\n",
    "epoch_files = []\n",
    "\n",
    "for subject in full_dataset:\n",
    "    subj_epoch_path = meg + '/' + subject + '/' + subject + '_rejection-epo.fif'\n",
    "    print(subj_epoch_path)\n",
    "    epoch_files.append(subj_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6d1f1-b124-4a01-8f6e-ad342211117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_full_data = [] \n",
    "labels_full_data = []\n",
    "for epoch_file in tqdm(epoch_files):\n",
    "    print(epoch_file)\n",
    "    epochs = mne.read_epochs(epoch_file)\n",
    "    epochs = epochs.resample(125)\n",
    "    epochs = epochs.crop(tmin=0. , tmax= 0.6)\n",
    "    epochs = mne.epochs.combine_event_ids(epochs, ['0Suff NW', '0Suff w/o Lat.', '0Suff w/ Lat'],  {'0Suff': 100},  True)\n",
    "    epochs = mne.epochs.combine_event_ids(epochs, ['1Suff PseudoStemNW', '1Suff RealStemNW', '1Suff w/ Lat.', '1Suff w/o Lat.'],  {'1Suff': 101},  True)\n",
    "    epochs = mne.epochs.combine_event_ids(epochs, ['2Suff RealStemNW', '2Suff PseudoStemNW', '2Suff w/ Lat.', '2Suff w/o Lat.', '2Suff Composite'],  {'2Suff': 102},  True)  \n",
    "    meg_full_data.append(epochs.get_data())\n",
    "    labels_full_data.append(epochs.events[:, 2])\n",
    "    del epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7cbba-d5b6-4f25-8a9a-aed24c2464c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_full_data = np.vstack(meg_full_data)\n",
    "labels_full_data = np.concatenate(labels_full_data)\n",
    "np.save('./meg_full_data.npy', meg_full_data)\n",
    "np.save('./labels.npy', labels_full_data)\n",
    "print(\"meg full data shape: \", meg_full_data.shape, labels_full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d79739-d8d4-493d-92fd-551464d7d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_full_data = np.where(labels_full_data == 100, 0, labels_full_data)\n",
    "labels_full_data = np.where(labels_full_data == 101, 1, labels_full_data)\n",
    "labels_full_data = np.where(labels_full_data == 102, 2, labels_full_data)\n",
    "np.unique(labels_full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93ba32-29de-4a40-a127-c3a08d698a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification using GRU\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, GRU, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the model architecture with increased complexity\n",
    "input_layer = Input(shape=meg_full_data.shape[1:])\n",
    "\n",
    "# Increase the number of units and add more layers\n",
    "x = GRU(128, return_sequences=True)(input_layer)\n",
    "x = Dropout(0.2)(x)  # Add dropout for regularization\n",
    "x = GRU(128, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)  # Add dropout for regularization\n",
    "x = GRU(128)(x)  # Last GRU layer does not return sequences\n",
    "x = Dropout(0.2)(x)  # Add dropout for regularization\n",
    " \n",
    "# Increase the complexity of the model further by adding Dense layers before the output\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)  # Add dropout for regularization\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)  # Add dropout for regularization\n",
    "\n",
    "output_layer = Dense(len(np.unique(labels_full_data)), activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebadb72-348b-46ef-a980-6b71676bd3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = meg_full_data.copy()\n",
    "y = labels_full_data.copy()\n",
    "\n",
    "losses = []\n",
    "metrics = []\n",
    "\n",
    "for subj in range(24):\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    print(\"Treating subject \", subj,\" as the test subj:\")\n",
    "    start = subj*1886\n",
    "    end = 1886*(subj+1)\n",
    "    X_test = X[start:end]\n",
    "    y_test = y[start:end]\n",
    "    X_train = np.delete(X, slice(start, end), axis=0)\n",
    "    y_train = np.delete(y, slice(start, end), axis=0)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    model.fit(X_train, y_train, batch_size=64, epochs=30, verbose=True)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    losses.append(loss)\n",
    "    metrics.append(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05f962d-173a-4b5c-a2fb-ec127c5d595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\\n Test Performance: \n",
    "              Loss: {:.4f} +/- {:.4f}.\n",
    "              Metric: {:.4f} +/- {:.4f}\"\"\"\n",
    "              .format(np.mean(losses), \n",
    "                      np.std(losses),\n",
    "                      np.mean(metrics), \n",
    "                      np.std(metrics)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aifsr_env",
   "language": "python",
   "name": "aifsr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
